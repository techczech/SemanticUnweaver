
import { Chunk, GlobalAnalysisResult, Granularity } from "../types";
import { runPrompt } from "./llm_core";

export const performGlobalAnalysis = async (chunks: Chunk[]): Promise<GlobalAnalysisResult> => {
  // Aggregate a representative sample (first 8000 chars)
  // We take a larger sample now to get better quotes
  const sampleText = chunks
    .slice(0, 30) 
    .map(c => c.text)
    .join('\n\n')
    .substring(0, 8000);

  const result = await runPrompt("global_analysis", { TEXT_SAMPLE: sampleText });

  return {
    genre: result.genre,
    summary: result.summary,
    themes: result.themes, // Structured themes
    potentialThemes: result.themes.map((t: any) => t.name), // Backward compat for simple string list if needed
    suggestedGranularity: Granularity.PARAGRAPH, // Legacy field
    suggestedLens: "THEMATIC", // Legacy field
    reasoning: "Generated by Step 3"
  };
};